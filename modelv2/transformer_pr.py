import torch
import torch.nn as nn

""" 
    TODO: Create a transformer model that can read complex handwritten text
    - As much as possible make it encoder only for simplicity
    Rule 1: Simply the architecture compare to the previous model architecture
    Rule 2: Better accuracy compare to previous model
    Rule 3: Prevent Overfitting!
    Rule 4: Training with mixed dataset (Real data, Generated data, Medical words)
"""

class PositionalEncoding(nn.Module):
    def __init__(self):
        super().__init__()
        pass

    def forward(self, x):
        pass

class InputEmbeddings(nn.Module):
    def __init__(self):
        super().__init__()
        pass

    def forward(self, x):
        pass

class AttentionLayer(nn.Module):
    def __init__(self):
        super().__init__()
        pass

    def forward(self, x):
        pass

class EncoderMLPLayer(nn.Module):
    def __init__(self):
        super().__init__()
        pass

    def forward(self, x):
        pass

class EncoderLayer():
    def __init__(self):
        super().__init__()
        pass

    def forward(self, x):
        pass

class MLPLayer(nn.Module):
    def __init__(self):
        super().__init__()
        pass

    def forward(self, x):
        pass
